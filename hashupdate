#!/usr/bin/env python 
# Print new files and their hashes from a given HASHDEEP file.

import argparse
import csv
import hashlib
import itertools
import os
import sys

from pathlib import Path

HEADER = 5    # First five lines are comments
SIZE = 0      # First column is file size
MD5 = 1       # Secood column is MD5 hash
SHA256 = 2    # Third column is SHA256 hash
FILENAME = 3  # Forth column is file name

def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument('files', nargs='*', type=Path)
    parser.add_argument('-f', '--file', default='HASHDEEP', 
        type=argparse.FileType('r'), help="HASHDEEP file to update")
    parser.add_argument('-r', '--recursive', action='store_true',
        help="Recursive mode: all subdirectories are traversed")
    parser.add_argument('-l', '--list', action='store_true',
        help="List new files without sizes and hashes")
    parser.add_argument('--list-changed-only', action='store_true',
        help="List changed or missing files")
    parser.add_argument('-c', '--check', action='store_true',
        help="Check that files in HASHDEEP still exist")
    return parser.parse_args()

def load_hash_file(file, check=False, list_changes=False):
    csvfile = csv.reader(file)
    hashes = {}

    for row in itertools.islice(csvfile, HEADER, None):
        path = row[FILENAME]
        if path in hashes:
            print(f"WARNING: duplicate file {path} found in {file}", 
                  file=sys.stderr)
        else:
            hashes[path] = row
            try:
                if check and Path(path).stat().st_size != int(row[SIZE]):
                    print(f"WARNING: file size has changed: {path}",
                        file=sys.stderr)
                if list_changes and Path(path).stat().st_size != int(row[SIZE]):
                    print(f"{path}", file=sys.stderr)
            except FileNotFoundError as e:
                if not list_changes:
                    print(f"{e}", file=sys.stderr)
                else:
                    print(f"{path}", file=sys.stderr)
                    
    if list_changes:
        sys.exit(0)

    return hashes


def checksums(path):
    md5 = hashlib.md5()
    sha256 = hashlib.sha256()

    with open(path, "rb") as f:
        while block := f.read(8192):
            md5.update(block)
            sha256.update(block)
    return md5.hexdigest(), sha256.hexdigest()


def new_files(args, hashes):
    if args.recursive:
        for path in args.files:
            for root, _, files in os.walk(path, topdown=False):
                for name in files:
                    path = Path(root) / name
                    if str(path) not in hashes:
                        if not args.list:
                            md5, sha256 = checksums(path)
                            print(f"{path.stat().st_size},{md5},{sha256},{path}")
                        else:
                            print(f"{path}")

def main():
    args = parse_args()
    hashes = load_hash_file(args.file, args.check, args.list_changed_only)

    new_files(args, hashes)

if __name__ == "__main__":
    main()
